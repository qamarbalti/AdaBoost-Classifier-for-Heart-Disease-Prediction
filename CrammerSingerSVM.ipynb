{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Notebook created by Mahdiyeh Behjat Khatooni\n",
        "# Date: 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z6IpE4S1FH5T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn import datasets, metrics, svm\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from itertools import cycle\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLlKZD-9RBWk"
      },
      "source": [
        "data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhto_fjIE8Jz",
        "outputId": "63d15a8a-9719-4c05-f230-ca87792acea6"
      },
      "outputs": [],
      "source": [
        "%cd drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HipqdEuGFCns",
        "outputId": "a6362464-73bf-4fdc-a146-8d1faf99e1b7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riYpUjx3FRA0",
        "outputId": "318086e9-5fe8-47ef-a2fd-a0313ecdcc8f"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "# unzip data set\n",
        "train_file = gzip.open('mnist/train-images-idx3-ubyte.gz','r')\n",
        "\n",
        "image_size = 28\n",
        "train_examples = 60000\n",
        "\n",
        "import numpy as np\n",
        "# train set\n",
        "train_file.read(16)\n",
        "train_buf = train_file.read()\n",
        "train_data = np.frombuffer(train_buf, dtype=np.uint8).astype(np.float32)\n",
        "train_data = train_data.reshape(train_examples, image_size, image_size)\n",
        "train_vectors = []\n",
        "for v in range(60000):\n",
        "  train_vectors.append(train_data[v].reshape(-1))\n",
        "  train_image = np.asarray(train_data[v]).squeeze()\n",
        "  # if u want to show examples make free below lines\n",
        "  #plt.imshow(train_image)\n",
        "  #plt.show()\n",
        "# I created feature vectors as a 1*784 vector for each example in data set\n",
        "#plt.show(train_vectors[10])\n",
        "print(len(train_vectors))\n",
        "\n",
        "# test set\n",
        "test_examples = 10000\n",
        "test_file = gzip.open('mnist/t10k-images-idx3-ubyte.gz','r')\n",
        "test_file.read(16)\n",
        "test_buf = test_file.read()\n",
        "test_data = np.frombuffer(test_buf, dtype=np.uint8).astype(np.float32)\n",
        "test_data = test_data.reshape(test_examples , image_size, image_size)\n",
        "test_vectors = []\n",
        "for v in range(10000):\n",
        "  test_vectors.append(test_data[v].reshape(-1))\n",
        "  test_image = np.asarray(test_data[v]).squeeze()\n",
        "  # if u want to show examples make free below lines\n",
        "  #plt.imshow(test_image)\n",
        "  #plt.show()\n",
        "#print(test_vectors[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_BYM_vaFR2s",
        "outputId": "cf40e300-7142-48dc-8c7f-0895e08201f1"
      },
      "outputs": [],
      "source": [
        "# train labels\n",
        "train_label = gzip.open('mnist/train-labels-idx1-ubyte.gz','r')\n",
        "train_label.read(8)\n",
        "label_buffer = train_label.read()\n",
        "train_labels = np.frombuffer(label_buffer, dtype=np.uint8).astype(np.int64)\n",
        "\n",
        "print(len(train_labels))\n",
        "# test labels\n",
        "test_label = gzip.open('mnist/t10k-labels-idx1-ubyte.gz','r')\n",
        "test_label.read(8)\n",
        "label_buffer = test_label.read()\n",
        "test_labels = np.frombuffer(label_buffer, dtype=np.uint8).astype(np.int64)\n",
        "\n",
        "print(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "sjDhgODjOxc4",
        "outputId": "a3d2e46b-a899-4673-c17c-ab2080dc97f9"
      },
      "outputs": [],
      "source": [
        "# Show some of the images\n",
        "num_images_to_show = 10\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(num_images_to_show):\n",
        "    plt.subplot(1, num_images_to_show, i+1)\n",
        "    plt.imshow(train_data[i+10], cmap='gray')\n",
        "    plt.title(f\"Label: {train_labels[i+10]}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRtVLQFVTbKw",
        "outputId": "a3f1fb99-e88f-47b5-9a8e-a10f7a617101"
      },
      "outputs": [],
      "source": [
        "def select_samples_per_class(x_data, y_data, num_samples):\n",
        "    selected_indices = []\n",
        "    for class_label in np.unique(y_data):\n",
        "        class_indices = np.where(y_data == class_label)[0]\n",
        "        selected_indices.extend(np.random.choice(class_indices, num_samples, replace=False))\n",
        "    x_data = np.array(x_data)\n",
        "    return x_data[selected_indices], y_data[selected_indices]\n",
        "\n",
        "# Choose 200 examples per class for the training set\n",
        "num_train_samples_per_class = 500\n",
        "x_train_selected, y_train_selected = select_samples_per_class(train_vectors, train_labels, num_train_samples_per_class)\n",
        "\n",
        "# Choose 50 examples per class for the test subset\n",
        "num_test_samples_per_class = 100\n",
        "x_test_selected, y_test_selected = select_samples_per_class(test_vectors, test_labels, num_test_samples_per_class)\n",
        "print(x_train_selected.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KwF8m7n6Tfuc"
      },
      "outputs": [],
      "source": [
        "# Shuffle the selected training data\n",
        "shuffle_indices = np.random.permutation(len(x_train_selected))\n",
        "x_train_subset = x_train_selected[shuffle_indices]\n",
        "y_train_subset = y_train_selected[shuffle_indices]\n",
        "\n",
        "# Split the test subset into features and labels\n",
        "x_test_subset, y_test_subset = x_test_selected, y_test_selected\n",
        "\n",
        "\n",
        "# # Normalize the pixel values to the range [0, 1]\n",
        "x_train_subset = x_train_subset.astype('float32') / 255.0\n",
        "x_test_subset = x_test_subset.astype('float32') / 255.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KXsV2ADUTwqR"
      },
      "outputs": [],
      "source": [
        "# Split dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = x_train_subset, x_test_subset, y_train_subset , y_test_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiQv2ZuuVnue"
      },
      "outputs": [],
      "source": [
        "# Split dataset into train and test sets\n",
        "# X_train, X_test, y_train, y_test = train_vectors, test_vectors, train_labels , test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4-CTOBlT5tY",
        "outputId": "3507b4d2-1085-49ed-97f5-b63b22cd469c"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape,X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lTwFA_ZLVdRu"
      },
      "outputs": [],
      "source": [
        "# Perform PCA for dimensionality reduction\n",
        "n_components = 100\n",
        "pca = PCA(n_components=n_components)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "362-Ggo0OrKf"
      },
      "source": [
        "# Crammer Singer Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgWOwM86PrIn"
      },
      "source": [
        "Just set hyperparameters and start running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Brofam5QRehi"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6PEZso6XSFnl"
      },
      "outputs": [],
      "source": [
        "class CrammerSingerSVM:\n",
        "  def __init__(self,X_train,Y_train,X_test,Y_test,threshold,max_iter,beta=1.0,epsilon=0.001,epsilon_0=0.001,kernel_function='RBF',gamma='scale',degree=5):\n",
        "    self.beta = beta\n",
        "    self.epsilon = epsilon\n",
        "    self.epsilon_0 = epsilon_0\n",
        "    self.kernel_function = kernel_function\n",
        "    self.gamma = gamma\n",
        "    self.degree = degree\n",
        "    self.X_train = X_train\n",
        "    self.X_test = X_test\n",
        "    self.Y_test = Y_test\n",
        "    self.threshold = threshold\n",
        "    self.max_iter = max_iter\n",
        "\n",
        "\n",
        "    classes = np.unique(Y_train)\n",
        "    self.num_classes = len(classes)\n",
        "    self.num_examples = self.X_train.shape[0]\n",
        "    self.num_features = self.X_train.shape[1]\n",
        "\n",
        "    self.Tau = np.zeros((self.num_examples,self.num_classes)) # i*r\n",
        "\n",
        "    Y_train = np.array(Y_train).reshape(-1, 1)\n",
        "    delta_train = OneHotEncoder(sparse_output=False).fit_transform(Y_train)     #one_hot_labels\n",
        "    self.Y_train = delta_train\n",
        "\n",
        "    self.F = (-1*self.beta) * self.Y_train\n",
        "\n",
        "    self.A = []\n",
        "    for index, row in enumerate(self.X_train):\n",
        "      K_i_i = self.kernel(self.kernel_function,row , row)\n",
        "      self.A.append(K_i_i)\n",
        "    self.A = np.array(self.A) # a vector\n",
        "\n",
        "\n",
        "  def kernel(self,kernel_function,a,b):\n",
        "\n",
        "    match kernel_function:\n",
        "      case 'linear':\n",
        "        return np.dot(a,b.T)\n",
        "\n",
        "      case 'polynomial':\n",
        "        return (np.dot(a, b.T) + 1) ** self.degree\n",
        "\n",
        "      case 'RBF':\n",
        "        if self.gamma == 'scale':\n",
        "          self.gamma = 1 / (self.num_features * self.X_train.var())\n",
        "          print(\"gamma=\",self.gamma)\n",
        "        return np.exp(-self.gamma*np.linalg.norm(np.array(a) - np.array(b)) ** 2 )\n",
        "\n",
        "  def runSVM(self):\n",
        "    self.Tau = self.train_machine() #multipliers(weights)\n",
        "    self.norms = np.linalg.norm(self.Tau, ord=2, axis=1)\n",
        "    # non_zero_indices = np.argwhere((norms >= self.threshold).any())\n",
        "    non_zero_indices = []\n",
        "    for i, norm in enumerate(self.norms):\n",
        "      print(\"pattern\" , i , \"norm:\" , norm)\n",
        "      if norm > self.threshold:\n",
        "        non_zero_indices.append(i)\n",
        "\n",
        "    self.support_weights = np.squeeze(self.Tau[non_zero_indices])\n",
        "    self.support_patterns = np.squeeze(self.X_train[non_zero_indices])\n",
        "    self.support_labels = np.squeeze(self.Y_train[non_zero_indices])\n",
        "    # self.visualizePatterns()\n",
        "\n",
        "    print(\"I am in Predict phase.\")\n",
        "    print(\"Number of Support Patterns\" , len(non_zero_indices))\n",
        "\n",
        "    H_matrix_train = []\n",
        "    for i,ex in enumerate(self.X_train):\n",
        "      H_matrix_train.append(self.predict(ex))\n",
        "    H_matrix_train = np.array(H_matrix_train)\n",
        "\n",
        "    H_matrix_test = []\n",
        "    for i,ex in enumerate(self.X_test):\n",
        "      H_matrix_test.append(self.predict(ex))\n",
        "\n",
        "    H_matrix_test = np.array(H_matrix_test)\n",
        "    return H_matrix_train , H_matrix_test # containing class for each test data point\n",
        "    # return H_matrix_test\n",
        "\n",
        "\n",
        "  def predict(self,x):\n",
        "    # calculating confidence score for each label for sample x #\n",
        "    num_support_patterns = self.support_patterns.shape[0]\n",
        "    output_x = np.zeros(self.num_classes)\n",
        "    for r in range(self.num_classes):\n",
        "      summation = 0\n",
        "      for i in range(num_support_patterns):\n",
        "        summation = summation + (self.support_weights[i][r] * self.kernel(self.kernel_function,x,self.support_patterns[i]))\n",
        "      output_x[r] = summation\n",
        "\n",
        "\n",
        "    predicted_label = np.argmax(output_x)\n",
        "    return predicted_label\n",
        "\n",
        "\n",
        "  def train_machine(self):\n",
        "    optimized = False\n",
        "    index_holder = [] # a list\n",
        "    iter = 0\n",
        "    while not optimized:\n",
        "      print(\"Round:\" , iter)\n",
        "      example_idx , psi = self.example_selection(self.X_train,self.Y_train,self.F,self.Tau)\n",
        "      index_holder.append(example_idx)\n",
        "      A_ex = self.A[example_idx] # a scalar\n",
        "      label_ex = self.Y_train[example_idx]\n",
        "      B_ex = self.calculate_B(example_idx,self.beta,self.X_train,label_ex,self.kernel_function,self.Tau)\n",
        "      sum_D_r = 0\n",
        "      D_ex = np.zeros(self.num_classes)\n",
        "      for r in range(self.num_classes):\n",
        "        D_r = np.array((self.F[example_idx][r] / A_ex) - self.Tau[example_idx][r] + label_ex[r])\n",
        "        D_ex[r] = D_r\n",
        "\n",
        "      sum_D_r = sum(D_ex)\n",
        "\n",
        "      theta = ((1/self.num_classes) * sum_D_r) - (1/self.num_classes)\n",
        "      Tau_ex_optimum = self.FixedPointAlgorithm(D_ex,theta,self.epsilon/2,A_ex,B_ex)\n",
        "      difference_tau = Tau_ex_optimum - self.Tau[example_idx] # for example p\n",
        "      self.F = self.update_F(self.F,difference_tau,self.kernel_function,example_idx,self.X_train)\n",
        "      self.Tau[example_idx] = Tau_ex_optimum\n",
        "\n",
        "      if psi[example_idx] < self.epsilon * self.beta or iter == self.max_iter:\n",
        "      # or index_holder.count(example_idx) >= 3:\n",
        "        optimized = True\n",
        "      iter += 1\n",
        "\n",
        "    return self.Tau #matrix containing weights of samples(support vectors)\n",
        "\n",
        "\n",
        "  def example_selection(self,data,data_labels,F,Tau):\n",
        "\n",
        "    psi_matrix = np.zeros(self.num_examples)\n",
        "    for i , ex in enumerate(data):\n",
        "      F_i = F[i] # a vector\n",
        "      F_i_max = np.max(F_i) # maximum confidence score assigning to label r\n",
        "      smaller_idx = []\n",
        "      for r in range(self.num_classes):\n",
        "        if Tau[i][r] < data_labels[i][r]:\n",
        "          smaller_idx.append(r)\n",
        "      F_i_min = np.min(F_i[smaller_idx]) # there must be at least one label r that satisfies this condition\n",
        "      psi = F_i_max - F_i_min\n",
        "      psi_matrix[i] = psi\n",
        "\n",
        "    p_idx = np.argmax(psi_matrix)\n",
        "\n",
        "    return p_idx , psi_matrix\n",
        "\n",
        "  def FixedPointAlgorithm(self,D,theta,epsilon,A,B):\n",
        "    l = 0\n",
        "    theta_l = theta\n",
        "    while True:\n",
        "      l += 1\n",
        "      max_array = np.zeros(self.num_classes)\n",
        "      for r in range(self.num_classes):\n",
        "        max_array[r] = max(theta_l,D[r])\n",
        "      theta_l_prim = (1/self.num_classes * sum(max_array)) - 1 / self.num_classes\n",
        "      if abs((theta_l - theta_l_prim) / theta_l) <= epsilon:\n",
        "        break\n",
        "      else:\n",
        "        theta_l = theta_l_prim\n",
        "\n",
        "    V = np.zeros(self.num_classes)\n",
        "    for r in range(self.num_classes):\n",
        "      b = min(theta_l_prim,D[r])\n",
        "      V[r] = b\n",
        "\n",
        "    Tau_star = V - (B / A)\n",
        "    return Tau_star\n",
        "\n",
        "  def calculate_B(self,p,beta,data,label_p,kernel_function,Tau):\n",
        "    summation = np.zeros(self.num_classes)\n",
        "    for i , x in enumerate(data):\n",
        "      if i != p:\n",
        "        holder = self.kernel(kernel_function,data[p],data[i])\n",
        "        summation = summation + (holder * Tau[i]) # a row\n",
        "\n",
        "    Bp = (-1 * beta * label_p) + summation  # a vector\n",
        "    return Bp\n",
        "\n",
        "  def update_F(self,F,difference_tau,kernel_function,p,data):\n",
        "    for m in range(self.num_examples):\n",
        "      kernel_result = self.kernel(kernel_function,data[p],data[m])\n",
        "\n",
        "      for r in range(self.num_classes):\n",
        "        F[m][r] = F[m][r] + (difference_tau[r] * kernel_result)\n",
        "\n",
        "    return F\n",
        "\n",
        "                                        ### Visualization ####\n",
        "  def visualizePatterns(self):\n",
        "    # min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    # X_normal = min_max_scaler.fit_transform(X)\n",
        "    for x in self.X_train:\n",
        "      if x not in self.support_patterns:\n",
        "        plt.scatter(x[0], x[1] , c='blue',edgecolors='k',marker='o',)\n",
        "      else:\n",
        "        plt.scatter(x[0], x[1] , c = 'green',marker='x')\n",
        "    plt.title(\"Multi Class SVM blob data with Support Patterns\")\n",
        "    return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XkIBsaAMjk2"
      },
      "source": [
        "Build your instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "peMQVeZISOJ0"
      },
      "outputs": [],
      "source": [
        "crammerSinger_instance = CrammerSingerSVM(X_train,y_train,X_test,y_test,threshold=0.0,max_iter = 2000,beta = 1e-2,epsilon =0.01,kernel_function='linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_7ww0gbSQ9P",
        "outputId": "eb9c9002-9ee5-4878-d6e3-68db6d438999"
      },
      "outputs": [],
      "source": [
        "y_pred_train , y_pred = crammerSinger_instance.runSVM()\n",
        "# y_pred = crammerSinger_instance.runSVM()\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "HwNUxbkVSie2",
        "outputId": "83a64f28-eea3-4862-fe8f-ed09661cc601"
      },
      "outputs": [],
      "source": [
        "disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Train Accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "# precision\n",
        "precision = precision_score(y_test , y_pred , average = 'micro')\n",
        "print(\"precision :\" , precision)\n",
        "# recall\n",
        "recall = recall_score(y_test, y_pred , average='micro')\n",
        "print(\"recall : \" , recall)\n",
        "# F1 score\n",
        "print(\"f1_score: \" , f1_score(y_test, y_pred , average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "QrCQNKBaSie2",
        "outputId": "83ab84eb-63b2-46c9-c6c1-e21f03b99c63"
      },
      "outputs": [],
      "source": [
        "# binarize the output\n",
        "# remove this and at last calculate to not come binarize values before this part\n",
        "\n",
        "binarize_prediction_values = label_binarize(y_pred, classes=[0, 1, 2 , 3 , 4 , 5 , 6 , 7 ,8 , 9])\n",
        "binarizes_test_labels = label_binarize(y_test, classes=[0, 1, 2 , 3 , 4 , 5 , 6 , 7 ,8 , 9])\n",
        "n_classes = 10\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "lw=2\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(binarizes_test_labels[:, i], binarize_prediction_values[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "colors = cycle(['blue', 'red', 'green','purple', 'orange', 'cyan','yellow', 'brown', 'magenta','black'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([-0.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic for multi-class data')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# AUC\n",
        "AUC= roc_auc_score(binarizes_test_labels, binarize_prediction_values , multi_class=\"ovr\", average=\"macro\")\n",
        "print(\"AUC:\" , AUC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epXWjZFwRD8v"
      },
      "source": [
        "# OVR single model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PhqU4KZnMqJm"
      },
      "outputs": [],
      "source": [
        "# Train a Logistic Regression classifier\n",
        "clf = SVC(C=...,kernel='...',decision_function_shape='ovr')\n",
        "clf.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = clf.predict(X_test_pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6EXc0laToeTa"
      },
      "outputs": [],
      "source": [
        "y_pred_train = clf.predict(X_train_pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "Q3UUkm7cOp6c",
        "outputId": "f0a4d8ac-48c3-4511-ac90-ec2f5e4cff27"
      },
      "outputs": [],
      "source": [
        "disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Accuracy\n",
        "Acc_train = accuracy_score(y_train, y_pred_train)\n",
        "print(f\"Accuracy: {Acc_train:.2f}\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "# precision\n",
        "precision = precision_score(y_test , y_pred , average = 'micro')\n",
        "print(\"precision :\" , precision)\n",
        "# recall\n",
        "recall = recall_score(y_test, y_pred , average='micro')\n",
        "print(\"recall : \" , recall)\n",
        "# F1 score\n",
        "print(\"f1_score: \" , f1_score(y_test, y_pred , average='micro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "7iFI061tHUTu",
        "outputId": "4ce4922c-f893-426e-c3a9-e2c5f24319d2"
      },
      "outputs": [],
      "source": [
        "# binarize the output\n",
        "# remove this and at last calculate to not come binarize values before this part\n",
        "\n",
        "binarize_prediction_values = label_binarize(y_pred, classes=[0, 1, 2 , 3 , 4 , 5 , 6 , 7 ,8 , 9])\n",
        "binarizes_test_labels = label_binarize(y_test, classes=[0, 1, 2 , 3 , 4 , 5 , 6 , 7 ,8 , 9])\n",
        "n_classes = 10\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "lw=2\n",
        "\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(binarizes_test_labels[:, i], binarize_prediction_values[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "colors = cycle(['blue', 'red', 'green','purple', 'orange', 'cyan','yellow', 'brown', 'magenta','black'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([-0.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic for multi-class data')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# AUC\n",
        "AUC= roc_auc_score(binarizes_test_labels, binarize_prediction_values , multi_class=\"ovr\", average=\"macro\")\n",
        "print(\"AUC:\" , AUC)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
